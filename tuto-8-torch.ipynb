{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'toc'></a>\n",
    "# Pytorch 101: An almost-comprehensive Pytorch tutorial for beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Disclaimer__: This tutorial is using PyTorch version 0.3.1, which is currently installed in Caltech GPU cluster. The newest release, 0.4.0, brings some fundamental changes, which I will mention in details of the tutorial. <br>\n",
    "\n",
    "Author: *Thong Q. Nguyen* <thong@caltech.edu>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. <a href='#intro'> Getting started</a><br>\n",
    "    a. <a href='#whatis'> What is PyTorch?</a><br>\n",
    "    b. <a href='#tensor'> Tensors</a><br>\n",
    "    c. <a href='#variable'> Variables</a><br>\n",
    "2. <a href='#build'> Building a neural network</a><br>\n",
    "    a. <a href='#module'> Modules and Parameters</a><br>\n",
    "    b. <a href='#loss'> Loss function</a><br>\n",
    "    c. <a href='#optim'> Optimizers</a><br>\n",
    "    d. <a href='#dummy'> A dummy model</a><br>\n",
    "    e. <a href='#remark'> Remark on training vs. validation</a><br>\n",
    "3. <a href='#data'> Loading data</a><br>\n",
    "    a. <a href='#dataset'> Dataset class</a><br>\n",
    "    b. <a href='#dataloader'> DataLoader</a><br>\n",
    "4. <a href='#parallel'>Parallel and distributed training</a><br>\n",
    "    a. <a href='#datapara'>Data-parallel training</a><br>\n",
    "    b. <a href='#distributed'>Distributed training</a><br>\n",
    "---\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "## Getting started\n",
    "\n",
    "\n",
    "<a id='whatis'></a>\n",
    "### What is PyTorch?\n",
    "PyTorch is a python-based scientific computing package serving 2 purposes:\n",
    "\n",
    "    1. replacement for NumPy to use the power of GPUs\n",
    "    2. deep learning research platform that provides maximum flexibility and speed\n",
    "    \n",
    "\n",
    "<a id='tensor'></a>\n",
    "### Tensors\n",
    "The power of PyTorch lies in its <a href='https://pytorch.org/docs/stable/tensors.html'>Tensor class </a>, which is similar to numpy arrays. However, PyTorch tensors (which I will from now on refer to as `Tensors`) can be sent to GPU to accelerate computing. Converting between `Tensors` and numpy arrays and vice versa are extremely easy. Note that the conversion is only possible on CPU. Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1,2\" # To select the GPU we want to use and mask out the occupied one\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n",
      "y = \n",
      " 0.2021\n",
      " 0.3481\n",
      " 0.8417\n",
      "[torch.FloatTensor of size 3x1]\n",
      "\n",
      "z = x + y = \n",
      " 0.2021  0.2021  0.2021\n",
      " 0.3481  0.3481  0.3481\n",
      " 0.8417  0.8417  0.8417\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a 3x3 Tensor of zeros\n",
    "x = torch.zeros([3, 3])\n",
    "print(\"x = {}\".format(x))\n",
    "# Create a random 3x1 Tensor \n",
    "y = torch.rand(3,1)\n",
    "print(\"y = {}\".format(y))\n",
    "# Tensor has broadcast property just like numpy \n",
    "z = x + y \n",
    "print(\"z = x + y = {}\".format(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device index: 0. Total devices: 2\n",
      "On GPU: z = \n",
      " 0.2021  0.2021  0.2021\n",
      " 0.3481  0.3481  0.3481\n",
      " 0.8417  0.8417  0.8417\n",
      "[torch.cuda.FloatTensor of size 3x3 (GPU 0)]\n",
      "\n",
      "Notice the type has now become torch.cuda.FloatTensor.\n",
      "Switching to a different device...\n",
      "Current device index: 1\n",
      "On a different GPU: z = \n",
      " 0.2021  0.2021  0.2021\n",
      " 0.3481  0.3481  0.3481\n",
      " 0.8417  0.8417  0.8417\n",
      "[torch.cuda.FloatTensor of size 3x3 (GPU 1)]\n",
      "\n",
      "On CPU: z = \n",
      " 0.2021  0.2021  0.2021\n",
      " 0.3481  0.3481  0.3481\n",
      " 0.8417  0.8417  0.8417\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send Tensor to GPU \n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device index: {}. Total devices: {}\".format(torch.cuda.current_device(), \n",
    "                                                               torch.cuda.device_count()))\n",
    "    torch.cuda.set_device(0)\n",
    "    z = z.cuda()\n",
    "    print(\"On GPU: z = {}\".format(z))\n",
    "    print(\"Notice the type has now become torch.cuda.FloatTensor.\")\n",
    "    # Now let's send it to a different GPU\n",
    "    print(\"Switching to a different device...\")\n",
    "    torch.cuda.set_device(1)\n",
    "    print(\"Current device index: {}\".format(torch.cuda.current_device()))\n",
    "    z = z.cuda()\n",
    "    print(\"On a different GPU: z = {}\".format(z))\n",
    "\n",
    "# Send Tensor back to CPU\n",
    "z = z.cpu()\n",
    "print(\"On CPU: z = {}\".format(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to numpy, z = <class 'numpy.ndarray'>\n",
      "[[0.20207632 0.20207632 0.20207632]\n",
      " [0.34811503 0.34811503 0.34811503]\n",
      " [0.8416593  0.8416593  0.8416593 ]]\n",
      "Converted to Tensor, z = \n",
      " 0.2021  0.2021  0.2021\n",
      " 0.3481  0.3481  0.3481\n",
      " 0.8417  0.8417  0.8417\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n",
      "Error: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). Use .cpu() to move the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "# Convert Tensor to Numpy array and vice versa\n",
    "import numpy as np\n",
    "z = x + y\n",
    "z = z.numpy()\n",
    "print(\"Converted to numpy, z = {}\\n{}\".format(type(z), z))\n",
    "\n",
    "z = torch.from_numpy(z)\n",
    "print(\"Converted to Tensor, z = {}\".format(z))\n",
    "\n",
    "# Note that the conversion is not possible when the Tensor is on GPU\n",
    "z = z.cuda()\n",
    "try:\n",
    "    z = z.numpy()\n",
    "except RuntimeError as e:\n",
    "    print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='variable'></a>\n",
    "### Variables\n",
    "<a href='#toc'> Back to top </a><br>\n",
    "\n",
    "*Note*: This concept of `Variables` only exists pre-0.4.0. In the 0.4.0 release, `Tensor` and `Variable` has been merged. However, it's good to understand the design philosophy of `Variables` which is fundamental to any neural network.\n",
    "\n",
    "`Variable` is essentially a wrapper of `Tensor` with 1 extra component: gradient. Recall that in a deep neural network, the optimization is done via a process called back-propagation. Given a function $f(\\mathbf{x})$ where $\\mathbf{x}$ is an input vector, we want to compute the gradient of $f$ at $x$, ie, $\\nabla _{x} f(\\mathbf{x})$. This gradient is computed with chain rule backwardly from the loss function. \n",
    "\n",
    "Fortunately, in PyTorch the gradient computation is handled automatically with the automatic differention package called *torch.autograd*. `Variable`, a class of this package, should be all you need for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Variable containing:\n",
      " 0.1055  0.8654\n",
      " 0.3135  0.6064\n",
      " 0.1207  0.8304\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = torch.rand(3,2)\n",
    "x = Variable(x)\n",
    "print(\"x = {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable has 2 component: Tensor and Gradient. Let's look at each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of x = \n",
      " 0.1055  0.8654\n",
      " 0.3135  0.6064\n",
      " 0.1207  0.8304\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "Gradient of x = None\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor of x = {}\".format(x.data))\n",
    "print(\"Gradient of x = {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient component is empty right now because there is no computation performed. Knowing these 2 basic concepts, we are ready to move forward to most the exciting part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build'></a>\n",
    "## Building a neural network\n",
    "<a href='#toc'> Back to top </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just kidding, there are few more concepts you need to know before building a network.\n",
    "\n",
    "<a id='module'></a>\n",
    "### Modules and Parameters\n",
    "`Modules` are the base class for all neural networks. A `Module` typically contains `Parameters`. `Parameters` are similar to `Variables` in the sense that they includes values (weights) and their corresponding gradients. `Parameters` have some extra built-in functions to use in a network's model. `Variables` and `Tensors` are usually just used for input and output data.  \n",
    "\n",
    "<a id='loss'></a>\n",
    "### Loss function\n",
    "Loss function is another module that takes `(prediction, target)` as inputs and computes how far away the prediction is from target. The loss function can then perform a backprop calculation to compute the gradients of the neural network modules.  \n",
    "\n",
    "<a id='optim'></a>\n",
    "### Optimizers\n",
    "The `Optimizer` takes `Parameters` of the model as inputs, and then update the `Parameters` once the gradients have been computed by the loss function's backpropagation.\n",
    "\n",
    "<a id='dummy'></a>\n",
    "### A dummy model\n",
    "<a href='#toc'> Back to top </a>\n",
    "\n",
    "\n",
    "Now you have all the ingradients, let's make an ultra-simple neural network to see how all the pieces are connected together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (dense1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (dense2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a model\n",
    "class Net(nn.Module): ### Network always has to be a subclass of nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(3,5)\n",
    "        self.dense2 = nn.Linear(5,1)\n",
    "    \n",
    "    def forward(self, x): # All the computation steps of the input are defined in this function\n",
    "        x = self.dense1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = F.relu(x) # Or you can compact all steps into x = F.relu(self.dense2(F.relu(self.dense1(x)))) \n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look deeper at the model we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "-0.4067  0.0955  0.0634\n",
      "-0.2292 -0.4204  0.3410\n",
      " 0.1078 -0.4060 -0.3278\n",
      " 0.2946  0.3949 -0.2251\n",
      "-0.1139 -0.5424 -0.1878\n",
      "[torch.FloatTensor of size 5x3]\n",
      ", Parameter containing:\n",
      "-0.4773\n",
      "-0.1040\n",
      " 0.5139\n",
      "-0.5131\n",
      " 0.1201\n",
      "[torch.FloatTensor of size 5]\n",
      ", Parameter containing:\n",
      " 0.0298 -0.2180 -0.0980  0.0778  0.0837\n",
      "[torch.FloatTensor of size 1x5]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " -4.5288\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net.parameters().__next__() # Get the parameter of the first layer, a 5x3 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer value: \n",
      "-0.4067  0.0955  0.0634\n",
      "-0.2292 -0.4204  0.3410\n",
      " 0.1078 -0.4060 -0.3278\n",
      " 0.2946  0.3949 -0.2251\n",
      "-0.1139 -0.5424 -0.1878\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "First layer gradient: None\n"
     ]
    }
   ],
   "source": [
    "print(\"First layer value: {}\".format(x.data))\n",
    "print(\"First layer gradient: {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a model, which contains 2 dense layers. The first layer is a 5x3 matrix, taking input of dimensionality `(N, C, 3)` where `N` is the batch size and `C` is number of channels. The output of the first layer would be of dimensionality `(N, C, 5)`, which is activated by a RELU function before fed into the second dense layer, a 5x1 matrix. The output is again activated by RELU before returning as the prediction of the given original input.\n",
    "\n",
    "Now we will define our loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # We use MSE which is the mean squared error between the predicted output and target.\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all the ingredients, let's input a fake data point and see how things go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = Variable containing:\n",
      " 0.8166  0.2665  0.9428\n",
      "[torch.FloatTensor of size 1x3]\n",
      "\n",
      "Target = Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.rand(1,3))\n",
    "target = Variable(torch.ones(1))\n",
    "print(\"Input = {}\".format(input))\n",
    "print(\"Target = {}\".format(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "prediction = net(input) # get the predicted output\n",
    "loss = criterion(prediction, target) # compute the MSE of our prediction with the target \n",
    "loss.backward() # Backprop to compute the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer value: \n",
      "-0.4067  0.0955  0.0634\n",
      "-0.2292 -0.4204  0.3410\n",
      " 0.1078 -0.4060 -0.3278\n",
      " 0.2946  0.3949 -0.2251\n",
      "-0.1139 -0.5424 -0.1878\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "First layer gradient: Variable containing:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First layer value: {}\".format(x.data))\n",
    "print(\"First layer gradient: {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! The layer's weights are unchanged but now we have the gradient, which is also the 5x3 matrix showing how the first layer should change to get closer to the target given the original input.\n",
    "\n",
    "Let's update the weights with newly computed gradients, and looks at the first layer again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer value: \n",
      "-0.4067  0.0955  0.0634\n",
      "-0.2292 -0.4204  0.3410\n",
      " 0.1078 -0.4060 -0.3278\n",
      " 0.2946  0.3949 -0.2251\n",
      "-0.1139 -0.5424 -0.1878\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "First layer gradient: Variable containing:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer.step() # Update the weight of the parameters\n",
    "print(\"First layer value: {}\".format(x.data))\n",
    "print(\"First layer gradient: {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last row of the matrix has been updated (with learning rate 0.01 we specified earlier). The gradient is still there, this is why we have to call `optimizer.zero_grad()` at every iteration, otherwise new gradients computed in the next step will add up to this old one and result in a crazy weight update. \n",
    "\n",
    "<a id='remark'></a>\n",
    "### Remark on training vs validation\n",
    "<a href='#toc'> Back to top </a>\n",
    "\n",
    "During training, all `Variables` and `Parameters` need to keep track of their gradients, which is quite computationally expensive. During the validation/testing phase, no gradient update is needed. Therefore, we need to set `net.train()` during training and `net.eval()` during testing. \n",
    "\n",
    "When wrapping the inputs and targets into `Variables` during the validation/testing phase, you need to set the `volatile` parameter, such as `inputs, targets = Variable(inputs, volatile=True), Variable(targets,volatile=True)` so that the memory won't explode during validation. Again, this is only true for pre-0.3.5 versions of PyTorch.\n",
    "\n",
    "---\n",
    "Hooray!!! We just went through all basic concepts of PyTorch, including tensor, gradient, module, optimizer, loss function and observed how they work together. However, there is still one important component you need to learn before applying to your own project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## Loading Data\n",
    "<a href='#toc'> Back to top </a>\n",
    "\n",
    "Generally, your data would be big enough to not being able to fit in your machine's memory. Typically, we have to write a data <a href=\"https://wiki.python.org/moin/Generators\">generator</a> to feed small portions of data to our network iteratively. Fortunately, there is built-in class in PyTorch that does this for us and all we need to do is to write our own Dataset class and pass it to the built-in generator class. \n",
    "\n",
    "<a id='dataset'></a>\n",
    "### Dataset class\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
    "     - __len__ so that len(dataset) returns the size of the dataset.\n",
    "     - __getitem__ to support the indexing such that dataset[i] can be used to get ith sample\n",
    "     \n",
    "<a id='dataloader'></a>\n",
    "### DataLoader \n",
    "<a href='#toc'> Back to top </a><br>\n",
    "`torch.utils.data.DataLoader` is an generator which takes our customized Dataset class as input and outputs each batch of dataset with the batch size specified by our own.\n",
    "\n",
    "The following example is excerpted from my own project. The dataset is stored in multiple HDF5 files located at `/bigdata/shared/LCDJets_Abstract_IsoLep_lt_20`. Each file in the dataset has 2 keys `Images` and `Labels`, where `Images` is a numpy array of size (750, 150, 94, 5) -- read: 750 images of size (150, 94, 5), where 5 is the number of channels and (150x94) is the WxH dimensions of the images. `Labels` are the 1-hot encoded target of the event types: QCD, $t \\bar{t}$, or $W$+jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "from glob import glob\n",
    "\n",
    "class EventImage(Dataset):\n",
    "\n",
    "    def check_data(self, file_names): \n",
    "        '''Count the number of events in each file and mark the threshold \n",
    "        boundaries between adjacent indices coming from 2 different files'''\n",
    "        num_data = 0\n",
    "        thresholds = [0]\n",
    "        for in_file_name in file_names:\n",
    "            h5_file = h5py.File( in_file_name, 'r' )\n",
    "            X = h5_file[self.feature_name]\n",
    "            if hasattr(X, 'keys'):\n",
    "                num_data += len(X[X.keys()[0]])\n",
    "                thresholds.append(num_data)\n",
    "            else:\n",
    "                num_data += len(X)\n",
    "                thresholds.append(num_data)\n",
    "            h5_file.close()\n",
    "        return (num_data, thresholds)\n",
    "\n",
    "    def __init__(self, dir_name, feature_name = 'Images', label_name = 'Labels'):\n",
    "        self.feature_name = feature_name\n",
    "        self.label_name = label_name\n",
    "        self.file_names = glob(dir_name+'/*.h5')\n",
    "        self.num_data, self.thresholds = self.check_data(self.file_names)\n",
    "\n",
    "    def is_numpy_array(self, data):\n",
    "        return isinstance(data, np.ndarray)\n",
    "\n",
    "    def get_num_samples(self, data):\n",
    "        \"\"\"Input: dataset consisting of a numpy array or list of numpy arrays.\n",
    "            Output: number of samples in the dataset\"\"\"\n",
    "        if self.is_numpy_array(data):\n",
    "            return len(data)\n",
    "        else:\n",
    "            return len(data[0])\n",
    "\n",
    "    def load_data(self, in_file_name):\n",
    "        \"\"\"Loads numpy arrays from H5 file.\n",
    "            If the features/labels groups contain more than one dataset,\n",
    "            we load them all, alphabetically by key.\"\"\"\n",
    "        h5_file = h5py.File( in_file_name, 'r' )\n",
    "        X = self.load_hdf5_data(h5_file[self.feature_name] )\n",
    "        Y = self.load_hdf5_data(h5_file[self.label_name] )\n",
    "        h5_file.close()\n",
    "        return X,Y\n",
    "    \n",
    "    def load_hdf5_data(self, data):\n",
    "        \"\"\"Returns a numpy array or (possibly nested) list of numpy arrays\n",
    "            corresponding to the group structure of the input HDF5 data.\n",
    "            If a group has more than one key, we give its datasets alphabetically by key\"\"\"\n",
    "        if hasattr(data, 'keys'):\n",
    "            out = [ self.load_hdf5_data( data[key] ) for key in sorted(data.keys()) ]\n",
    "        else:\n",
    "            out = data[:]\n",
    "        return out\n",
    "\n",
    "    def get_data(self, data, idx):\n",
    "        \"\"\"Input: a numpy array or list of numpy arrays.\n",
    "            Gets elements at idx for each array\"\"\"\n",
    "        if self.is_numpy_array(data):\n",
    "            return data[idx]\n",
    "        else:\n",
    "            return [arr[idx] for arr in data]\n",
    "\n",
    "    def get_index(self, idx):\n",
    "        \"\"\"Translate the global index (idx) into local indexes,\n",
    "        including file index and event index of that file\"\"\"\n",
    "        file_index = next(i for i,v in enumerate(self.thresholds) if v > idx)\n",
    "        file_index -= 1\n",
    "        event_index = idx - self.thresholds[file_index]\n",
    "        return file_index, event_index\n",
    "\n",
    "    def get_thresholds(self):\n",
    "        return self.thresholds\n",
    "\n",
    "    # Below are the two functions you are required to define\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_index, event_index = self.get_index(idx)\n",
    "        X, Y = self.load_data(self.file_names[file_index])\n",
    "        return {'Images': self.get_data(X, event_index), 'Labels': np.argmax(self.get_data(Y, event_index))}\n",
    "\n",
    "    \n",
    "# Define the data generators from the training set and validation set. Let's try a batch size of 12.\n",
    "train_set = EventImage(dir_name='/bigdata/shared/LCDJets_Abstract_IsoLep_lt_20//train/',\n",
    "                       feature_name ='Images',label_name = 'Labels')\n",
    "train_loader = DataLoader(train_set, batch_size=12, shuffle=True, num_workers=4)\n",
    "\n",
    "val_set = EventImage(dir_name='/bigdata/shared/LCDJets_Abstract_IsoLep_lt_20//val/',\n",
    "                     feature_name ='Images',label_name = 'Labels')\n",
    "val_loader = DataLoader(val_set, batch_size=12, shuffle=True , num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape = torch.Size([12, 150, 94, 5])\n",
      "Targets shape = torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(train_loader):\n",
    "    inputs, targets = data['Images'], data['Labels']\n",
    "    print(\"Inputs shape = {}\".format(inputs.shape))\n",
    "    print(\"Targets shape = {}\".format(targets.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got a pair of (input, target) from the data generator with batch size of 12. \n",
    "\n",
    "For an end-to-end training reference, please take a look at https://github.com/pytorch/examples/blob/0.3.1/mnist/main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parallel'></a>\n",
    "## Parallel and distributed training\n",
    "<a href='#toc'> Back to top </a><br>\n",
    "\n",
    "To be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
